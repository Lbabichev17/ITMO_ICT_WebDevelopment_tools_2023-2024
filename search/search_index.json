{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lab1 \u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 1 Lab2 \u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 2 Lab3 \u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 3","title":"Home"},{"location":"#lab1","text":"\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 1","title":"Lab1"},{"location":"#lab2","text":"\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 2","title":"Lab2"},{"location":"#lab3","text":"\u043b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 3","title":"Lab3"},{"location":"report1/","text":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 1 \u0417\u0430\u0434\u0430\u0447\u0430 : \u0420\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u043d\u043e\u0446\u0435\u043d\u043d\u043e\u0433\u043e \u0441\u0435\u0440\u0432\u0435\u0440\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0444\u0440\u0435\u0439\u043c\u0432\u043e\u0440\u043a\u0430 FastAPI \u0441 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0441\u0440\u0435\u0434\u0441\u0442\u0432 \u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a. \u0422\u0435\u043c\u0430 : \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u0438\u044f \u0445\u0430\u043a\u0430\u0442\u043e\u043d\u043e\u0432. \u041c\u043e\u0434\u0435\u043b\u0438 (lib/models.py) \u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : from datetime import datetime from enum import Enum from typing import Optional, List from sqlmodel import SQLModel, Field, Relationship from sqlalchemy import JSON class SkillEnum(str, Enum): frontend = \"Frontend\" backend = \"Backend\" fullstack = \"Fullstack\" devops = \"DevOps\" mobile = \"Mobile\" data_science = \"Data Science\" class UserTeam(SQLModel, table=True): team_id: Optional[int] = Field( default=None, foreign_key=\"team.id\", primary_key=True ) user_id: Optional[int] = Field( default=None, foreign_key=\"user.id\", primary_key=True ) position: str class UserProfile(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) user: Optional[\"User\"] = Relationship(back_populates=\"profile\") avatar: Optional[str] = None birth_date: Optional[str] = None skills: List[SkillEnum] = Field(sa_type=JSON) class UserDefault(SQLModel): username: str = Field(index=True) password: str = Field(max_length=256, min_length=6) class User(UserDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) teams: List[\"Team\"] = Relationship(back_populates=\"users\", link_model=UserTeam) profile_id: Optional[int] = Field(foreign_key=\"userprofile.id\") profile: UserProfile = Relationship(back_populates=\"user\") class UserWithProfile(UserDefault): profile: Optional[UserProfile] = None class TeamDefault(SQLModel): name: str class Team(TeamDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) name: str users: List[User] = Relationship(back_populates=\"teams\", link_model=UserTeam) projects: List[\"Project\"] = Relationship(back_populates=\"team\") class TeamWithUsers(TeamDefault): users: List[UserWithProfile] = [] class ProjectDefault(SQLModel): name: str description: Optional[str] expected_result: Optional[str] class Project(ProjectDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) team_id: int = Field(foreign_key=\"team.id\") team: Team = Relationship(back_populates=\"projects\") tasks: List[\"Task\"] = Relationship(back_populates=\"project\") class ProjectWithTasksAndTeam(ProjectDefault): tasks: List[\"Task\"] = [] team: Optional[Team] = None class TaskDefault(SQLModel): name: str description: Optional[str] = None deadline: Optional[datetime] = None class Task(TaskDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) project_id: int = Field(foreign_key=\"project.id\") project: Optional[Project] = Relationship(back_populates=\"tasks\") \u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c UserTeam \u043a\u0430\u043a \u0430\u0441\u0441\u043e\u0446\u0438\u0430\u0442\u0438\u0432\u043d\u0443\u044e \u0441\u0443\u0449\u043d\u043e\u0441\u0442\u044c - \u0438\u043c\u0435\u0435\u043c \u0434\u0432\u0430 \u0432\u043d\u0435\u0448\u043d\u0438\u0445 \u043a\u043b\u044e\u0447\u0430 (team_id \u0438 user_id), \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0432\u044f\u0437\u044b\u0432\u0430\u044e\u0442 \u0442\u0430\u0431\u043b\u0438\u0446\u044b team \u0438 user. \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441\u0432\u044f\u0437\u044c \u043c\u0435\u0436\u0434\u0443 \u0442\u0430\u0431\u043b\u0438\u0446\u0430\u043c\u0438 User \u0438 Team. \u042d\u0442\u0430 \u0441\u0432\u044f\u0437\u044c \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442, \u0447\u0442\u043e \u0443 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043a\u043e\u043c\u0430\u043d\u0434, \u0438 \u043a\u0430\u0436\u0434\u0430\u044f \u043a\u043e\u043c\u0430\u043d\u0434\u0430 \u043c\u043e\u0436\u0435\u0442 \u0438\u043c\u0435\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439. \u042d\u043d\u0434\u043f\u043e\u0438\u043d\u0442\u044b (endpoints/team.py, users.py) \u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u044d\u043d\u0434\u043f\u043e\u0438\u043d\u0442\u044b. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : from datetime import datetime from fastapi import APIRouter, Depends, HTTPException from typing import List from pydantic import BaseModel from sqlmodel import select from db import get_session from lib.models import (User, UserTeam, Team, Project, Task, TeamWithUsers, ProjectDefault, ProjectWithTasksAndTeam, TaskDefault) team_router = APIRouter() # ---- TEAMS ---- # Create new team @team_router.post(\"/teams\", response_model=Team) def create_team(team: Team, session=Depends(get_session)): session.add(team) session.commit() session.refresh(team) return team @team_router.get(\"/teams\", response_model=List[Team]) def get_all_teams(session=Depends(get_session)): teams = session.query(Team).all() return teams # Get team by id with information about all users @team_router.get(\"/teams/{team_id}\", response_model=TeamWithUsers) def get_team_by_id(team_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") return team class AddUserToTeamRequest(BaseModel): position: str # Add user (by id) to team @team_router.post(\"/teams/{team_id}/users/{user_id}\") def add_user_to_team(team_id: int, user_id: int, request_body: AddUserToTeamRequest, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") try: user_team = UserTeam(user_id=user.id, team_id=team.id, position=request_body.position) session.add(user_team) session.commit() except Exception as e: return {\"message\": \"User already in team\"} return {\"message\": \"User added to team successfully\"} # Delete user from team @team_router.delete(\"/teams/{team_id}/users/{user_id}\") def delete_user_from_team(team_id: int, user_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") try: team.users.remove(user) session.commit() except Exception as e: return {\"message\": \"User not in team\"} return {\"message\": \"User removed from team successfully\"} # Delete team @team_router.delete(\"/teams/{team_id}\") def delete_team(team_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") session.delete(team) session.commit() return {\"message\": \"Team deleted successfully\"} # ---- PROJECTS ---- # Create project @team_router.post(\"/projects/\", response_model=Project) def create_project(project_data: ProjectDefault, team_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") project = Project(team_id=team_id, **project_data.dict()) session.add(project) session.commit() session.refresh(project) return project # Get list of projects @team_router.get(\"/projects/\", response_model=List[Project]) def get_projects(session=Depends(get_session)): return session.query(Project).all() # Get project with task list by id @team_router.get(\"/projects/{project_id}/\", response_model=ProjectWithTasksAndTeam) def get_project_with_tasks(project_id: int, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") return project # Get list of projects of certain team by id @team_router.get(\"/teams/{team_id}/projects/\", response_model=List[Project]) def get_projects_by_team_id(team_id: int, session=Depends(get_session)): return session.exec(select(Project).where(Project.team_id == team_id)).all() # Update project information @team_router.put(\"/projects/{project_id}/\", response_model=Project) def update_project(project_id: int, project_data: ProjectDefault, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") for field, value in project_data.dict(exclude_unset=True).items(): setattr(project, field, value) session.commit() session.refresh(project) return project # Delete project @team_router.delete(\"/projects/{project_id}/\") def delete_project(project_id: int, session=Depends(get_session)): project = session.query(Project).filter(Project.id == project_id).first() if not project: raise HTTPException(status_code=404, detail=\"Project not found\") session.delete(project) session.commit() return {\"message\": \"Project deleted successfully\"} # ---- TASKS ---- # Create task @team_router.post(\"/tasks/\", response_model=Task) # /tasks/?project_id=value def create_task(task_data: TaskDefault, project_id: int, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") task = Task(project_id=project_id, **task_data.dict()) session.add(task) session.commit() session.refresh(task) return task # List all tasks @team_router.get(\"/tasks/\", response_model=List[Task]) def list_all_tasks(session=Depends(get_session)): return session.query(Task).all() # List all tasks of certain project @team_router.get(\"/projects/{project_id}/tasks/\", response_model=List[Task]) def list_tasks_by_project(project_id: int, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") return session.exec(select(Task).where(Task.project_id == project_id)).all() # Get certain task by id @team_router.get(\"/tasks/{task_id}/\", response_model=Task) def get_task_by_id(task_id: int, session=Depends(get_session)): task = session.get(Task, task_id) if not task: raise HTTPException(status_code=404, detail=\"Task not found\") return task # Update task by id @team_router.put(\"/tasks/{task_id}/\", response_model=Task) def update_task(task_id: int, task_data: Task, session=Depends(get_session)): task = session.get(Task, task_id) if not task: raise HTTPException(status_code=404, detail=\"Task not found\") for field, value in task_data.dict(exclude_unset=True).items(): setattr(task, field, value) session.commit() session.refresh(task) return task # List all tasks with missed deadlines @team_router.get(\"/tasks/urgent/\", response_model=List[Task]) def get_urgent_tasks(session=Depends(get_session)): urgent_tasks = session.exec(select(Task).where(Task.deadline < datetime.now())).all() return urgent_tasks # Delete task by id @team_router.delete(\"/tasks/{task_id}/\") def delete_task(task_id: int, session=Depends(get_session)): task = session.get(Task, task_id) if not task: raise HTTPException(status_code=404, detail=\"Task not found\") session.delete(task) session.commit() return {\"message\": \"Task deleted successfully\"} from datetime import datetime from fastapi import APIRouter, Depends, HTTPException from typing import List from sqlmodel import select from typing_extensions import TypedDict from auth import AuthHandler from db import get_session from lib.models import User, UserProfile, UserDefault, UserWithProfile from repos.users import find_user users_router = APIRouter() auth_handler = AuthHandler() @users_router.get(\"/users\") def get_users(session=Depends(get_session)) -> List[User]: return session.exec(select(User)).all() @users_router.patch(\"/users/{user_id}\", response_model=User) def update_user(user_id: int, profile_data: UserProfile, session=Depends(get_session)): user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") # Get the user's existing profile profile = user.profile # Update profile data profile_data_dict = profile_data.dict(exclude_unset=True) for key, value in profile_data_dict.items(): setattr(profile, key, value) session.commit() session.refresh(profile) return profile @users_router.get('/users/me', response_model=UserWithProfile) def get_current_user(user: User = Depends(auth_handler.get_current_user), session=Depends(get_session)): userWithProfile = session.get(User, user.id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") return userWithProfile # Get User by ID @users_router.get(\"/users/{user_id}\", response_model=UserWithProfile) def get_user(user_id: int, session=Depends(get_session)) -> User: user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") return user # Delete User @users_router.delete(\"/users/{user_id}\") def delete_user(user_id: int, session=Depends(get_session)) -> TypedDict('Response', {\"message\": str}): user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") session.delete(user) session.commit() return {\"message\": \"User deleted successfully\"} @users_router.post('/registration') def register(user_data: UserDefault, profile_data: UserProfile, session=Depends(get_session)) -> TypedDict('Response', {\"status\": int, \"message\": str}): users = session.exec(select(User)).all() if any(x.username == user_data.username for x in users): raise HTTPException(status_code=400, detail='Username is taken') hashed_pwd = auth_handler.get_password_hash(user_data.password) profile = UserProfile(**profile_data.dict()) session.add(profile) session.commit() session.refresh(profile) user = User(password=hashed_pwd, username=user_data.username) user.profile = profile session.add(user) session.commit() session.refresh(user) return {\"status\": 201, \"message\": \"User created successfully\"} @users_router.post('/login') def login(user: UserDefault) -> TypedDict('Response', {\"token\": str}): user_found = find_user(user.username) if not user_found: raise HTTPException(status_code=401, detail='Invalid username and/or password') verified = auth_handler.verify_password(user.password, user_found.password) if not verified: raise HTTPException(status_code=401, detail='Invalid username and/or password') token = auth_handler.encode_token(user_found.username) return {'token': token} \u0421\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0441 \u0411\u0414 (db.py, .env) \u041a\u043e\u0434 \u0441\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044f \u0441 \u0411\u0414. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : from sqlmodel import SQLModel, Session, create_engine from dotenv import load_dotenv import os load_dotenv() db_url = os.getenv(\"DATABASE_URL\") engine = create_engine(db_url, echo=True) def init_db(): SQLModel.metadata.create_all(engine) def get_session(): with Session(engine) as session: yield session DATABASE_URL=postgresql://postgres:admin@localhost/postgres \u0410\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 (auth.py) \u0410\u0443\u0442\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438 \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : import datetime from fastapi import Security, HTTPException from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials from passlib.context import CryptContext import jwt from starlette import status from repos.users import find_user class AuthHandler: security = HTTPBearer() pwd_context = CryptContext(schemes=['bcrypt']) secret = 'very-very-secret-key' def get_password_hash(self, password): return self.pwd_context.hash(password) def verify_password(self, pwd, hashed_pwd): return self.pwd_context.verify(pwd, hashed_pwd) def encode_token(self, user_id): payload = { 'exp': datetime.datetime.utcnow() + datetime.timedelta(hours=24), 'iat': datetime.datetime.utcnow(), 'sub': user_id } return jwt.encode(payload, self.secret, algorithm='HS256') def decode_token(self, token): try: payload = jwt.decode(token, self.secret, algorithms=['HS256']) return payload['sub'] except jwt.ExpiredSignatureError: raise HTTPException(status_code=401, detail='Expired signature') except jwt.InvalidTokenError: raise HTTPException(status_code=401, detail='Invalid token') def auth_wrapper(self, auth: HTTPAuthorizationCredentials = Security(security)): return self.decode_token(auth.credentials) def get_current_user(self, auth: HTTPAuthorizationCredentials = Security(security)): credentials_exception = HTTPException( status_code=status.HTTP_401_UNAUTHORIZED, detail='Could not validate credentials' ) username = self.decode_token(auth.credentials) if username is None: raise credentials_exception user = find_user(username) if user is None: raise credentials_exception return user","title":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 1"},{"location":"report1/#1","text":"\u0417\u0430\u0434\u0430\u0447\u0430 : \u0420\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u043d\u043e\u0446\u0435\u043d\u043d\u043e\u0433\u043e \u0441\u0435\u0440\u0432\u0435\u0440\u043d\u043e\u0433\u043e \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0444\u0440\u0435\u0439\u043c\u0432\u043e\u0440\u043a\u0430 FastAPI \u0441 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0441\u0440\u0435\u0434\u0441\u0442\u0432 \u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a. \u0422\u0435\u043c\u0430 : \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0441\u0438\u0441\u0442\u0435\u043c\u044b \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u0438\u044f \u0445\u0430\u043a\u0430\u0442\u043e\u043d\u043e\u0432.","title":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 1"},{"location":"report1/#libmodelspy","text":"\u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : from datetime import datetime from enum import Enum from typing import Optional, List from sqlmodel import SQLModel, Field, Relationship from sqlalchemy import JSON class SkillEnum(str, Enum): frontend = \"Frontend\" backend = \"Backend\" fullstack = \"Fullstack\" devops = \"DevOps\" mobile = \"Mobile\" data_science = \"Data Science\" class UserTeam(SQLModel, table=True): team_id: Optional[int] = Field( default=None, foreign_key=\"team.id\", primary_key=True ) user_id: Optional[int] = Field( default=None, foreign_key=\"user.id\", primary_key=True ) position: str class UserProfile(SQLModel, table=True): id: Optional[int] = Field(default=None, primary_key=True) user: Optional[\"User\"] = Relationship(back_populates=\"profile\") avatar: Optional[str] = None birth_date: Optional[str] = None skills: List[SkillEnum] = Field(sa_type=JSON) class UserDefault(SQLModel): username: str = Field(index=True) password: str = Field(max_length=256, min_length=6) class User(UserDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) teams: List[\"Team\"] = Relationship(back_populates=\"users\", link_model=UserTeam) profile_id: Optional[int] = Field(foreign_key=\"userprofile.id\") profile: UserProfile = Relationship(back_populates=\"user\") class UserWithProfile(UserDefault): profile: Optional[UserProfile] = None class TeamDefault(SQLModel): name: str class Team(TeamDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) name: str users: List[User] = Relationship(back_populates=\"teams\", link_model=UserTeam) projects: List[\"Project\"] = Relationship(back_populates=\"team\") class TeamWithUsers(TeamDefault): users: List[UserWithProfile] = [] class ProjectDefault(SQLModel): name: str description: Optional[str] expected_result: Optional[str] class Project(ProjectDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) team_id: int = Field(foreign_key=\"team.id\") team: Team = Relationship(back_populates=\"projects\") tasks: List[\"Task\"] = Relationship(back_populates=\"project\") class ProjectWithTasksAndTeam(ProjectDefault): tasks: List[\"Task\"] = [] team: Optional[Team] = None class TaskDefault(SQLModel): name: str description: Optional[str] = None deadline: Optional[datetime] = None class Task(TaskDefault, table=True): id: Optional[int] = Field(default=None, primary_key=True) project_id: int = Field(foreign_key=\"project.id\") project: Optional[Project] = Relationship(back_populates=\"tasks\") \u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, \u0440\u0430\u0441\u0441\u043c\u0430\u0442\u0440\u0438\u0432\u0430\u0435\u043c UserTeam \u043a\u0430\u043a \u0430\u0441\u0441\u043e\u0446\u0438\u0430\u0442\u0438\u0432\u043d\u0443\u044e \u0441\u0443\u0449\u043d\u043e\u0441\u0442\u044c - \u0438\u043c\u0435\u0435\u043c \u0434\u0432\u0430 \u0432\u043d\u0435\u0448\u043d\u0438\u0445 \u043a\u043b\u044e\u0447\u0430 (team_id \u0438 user_id), \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0432\u044f\u0437\u044b\u0432\u0430\u044e\u0442 \u0442\u0430\u0431\u043b\u0438\u0446\u044b team \u0438 user. \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u0442\u0441\u044f \u0441\u0432\u044f\u0437\u044c \u043c\u0435\u0436\u0434\u0443 \u0442\u0430\u0431\u043b\u0438\u0446\u0430\u043c\u0438 User \u0438 Team. \u042d\u0442\u0430 \u0441\u0432\u044f\u0437\u044c \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442, \u0447\u0442\u043e \u0443 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043a\u043e\u043c\u0430\u043d\u0434, \u0438 \u043a\u0430\u0436\u0434\u0430\u044f \u043a\u043e\u043c\u0430\u043d\u0434\u0430 \u043c\u043e\u0436\u0435\u0442 \u0438\u043c\u0435\u0442\u044c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439.","title":"\u041c\u043e\u0434\u0435\u043b\u0438 (lib/models.py)"},{"location":"report1/#endpointsteampy-userspy","text":"\u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u044d\u043d\u0434\u043f\u043e\u0438\u043d\u0442\u044b. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : from datetime import datetime from fastapi import APIRouter, Depends, HTTPException from typing import List from pydantic import BaseModel from sqlmodel import select from db import get_session from lib.models import (User, UserTeam, Team, Project, Task, TeamWithUsers, ProjectDefault, ProjectWithTasksAndTeam, TaskDefault) team_router = APIRouter() # ---- TEAMS ---- # Create new team @team_router.post(\"/teams\", response_model=Team) def create_team(team: Team, session=Depends(get_session)): session.add(team) session.commit() session.refresh(team) return team @team_router.get(\"/teams\", response_model=List[Team]) def get_all_teams(session=Depends(get_session)): teams = session.query(Team).all() return teams # Get team by id with information about all users @team_router.get(\"/teams/{team_id}\", response_model=TeamWithUsers) def get_team_by_id(team_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") return team class AddUserToTeamRequest(BaseModel): position: str # Add user (by id) to team @team_router.post(\"/teams/{team_id}/users/{user_id}\") def add_user_to_team(team_id: int, user_id: int, request_body: AddUserToTeamRequest, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") try: user_team = UserTeam(user_id=user.id, team_id=team.id, position=request_body.position) session.add(user_team) session.commit() except Exception as e: return {\"message\": \"User already in team\"} return {\"message\": \"User added to team successfully\"} # Delete user from team @team_router.delete(\"/teams/{team_id}/users/{user_id}\") def delete_user_from_team(team_id: int, user_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") try: team.users.remove(user) session.commit() except Exception as e: return {\"message\": \"User not in team\"} return {\"message\": \"User removed from team successfully\"} # Delete team @team_router.delete(\"/teams/{team_id}\") def delete_team(team_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") session.delete(team) session.commit() return {\"message\": \"Team deleted successfully\"} # ---- PROJECTS ---- # Create project @team_router.post(\"/projects/\", response_model=Project) def create_project(project_data: ProjectDefault, team_id: int, session=Depends(get_session)): team = session.get(Team, team_id) if not team: raise HTTPException(status_code=404, detail=\"Team not found\") project = Project(team_id=team_id, **project_data.dict()) session.add(project) session.commit() session.refresh(project) return project # Get list of projects @team_router.get(\"/projects/\", response_model=List[Project]) def get_projects(session=Depends(get_session)): return session.query(Project).all() # Get project with task list by id @team_router.get(\"/projects/{project_id}/\", response_model=ProjectWithTasksAndTeam) def get_project_with_tasks(project_id: int, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") return project # Get list of projects of certain team by id @team_router.get(\"/teams/{team_id}/projects/\", response_model=List[Project]) def get_projects_by_team_id(team_id: int, session=Depends(get_session)): return session.exec(select(Project).where(Project.team_id == team_id)).all() # Update project information @team_router.put(\"/projects/{project_id}/\", response_model=Project) def update_project(project_id: int, project_data: ProjectDefault, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") for field, value in project_data.dict(exclude_unset=True).items(): setattr(project, field, value) session.commit() session.refresh(project) return project # Delete project @team_router.delete(\"/projects/{project_id}/\") def delete_project(project_id: int, session=Depends(get_session)): project = session.query(Project).filter(Project.id == project_id).first() if not project: raise HTTPException(status_code=404, detail=\"Project not found\") session.delete(project) session.commit() return {\"message\": \"Project deleted successfully\"} # ---- TASKS ---- # Create task @team_router.post(\"/tasks/\", response_model=Task) # /tasks/?project_id=value def create_task(task_data: TaskDefault, project_id: int, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") task = Task(project_id=project_id, **task_data.dict()) session.add(task) session.commit() session.refresh(task) return task # List all tasks @team_router.get(\"/tasks/\", response_model=List[Task]) def list_all_tasks(session=Depends(get_session)): return session.query(Task).all() # List all tasks of certain project @team_router.get(\"/projects/{project_id}/tasks/\", response_model=List[Task]) def list_tasks_by_project(project_id: int, session=Depends(get_session)): project = session.get(Project, project_id) if not project: raise HTTPException(status_code=404, detail=\"Project not found\") return session.exec(select(Task).where(Task.project_id == project_id)).all() # Get certain task by id @team_router.get(\"/tasks/{task_id}/\", response_model=Task) def get_task_by_id(task_id: int, session=Depends(get_session)): task = session.get(Task, task_id) if not task: raise HTTPException(status_code=404, detail=\"Task not found\") return task # Update task by id @team_router.put(\"/tasks/{task_id}/\", response_model=Task) def update_task(task_id: int, task_data: Task, session=Depends(get_session)): task = session.get(Task, task_id) if not task: raise HTTPException(status_code=404, detail=\"Task not found\") for field, value in task_data.dict(exclude_unset=True).items(): setattr(task, field, value) session.commit() session.refresh(task) return task # List all tasks with missed deadlines @team_router.get(\"/tasks/urgent/\", response_model=List[Task]) def get_urgent_tasks(session=Depends(get_session)): urgent_tasks = session.exec(select(Task).where(Task.deadline < datetime.now())).all() return urgent_tasks # Delete task by id @team_router.delete(\"/tasks/{task_id}/\") def delete_task(task_id: int, session=Depends(get_session)): task = session.get(Task, task_id) if not task: raise HTTPException(status_code=404, detail=\"Task not found\") session.delete(task) session.commit() return {\"message\": \"Task deleted successfully\"} from datetime import datetime from fastapi import APIRouter, Depends, HTTPException from typing import List from sqlmodel import select from typing_extensions import TypedDict from auth import AuthHandler from db import get_session from lib.models import User, UserProfile, UserDefault, UserWithProfile from repos.users import find_user users_router = APIRouter() auth_handler = AuthHandler() @users_router.get(\"/users\") def get_users(session=Depends(get_session)) -> List[User]: return session.exec(select(User)).all() @users_router.patch(\"/users/{user_id}\", response_model=User) def update_user(user_id: int, profile_data: UserProfile, session=Depends(get_session)): user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") # Get the user's existing profile profile = user.profile # Update profile data profile_data_dict = profile_data.dict(exclude_unset=True) for key, value in profile_data_dict.items(): setattr(profile, key, value) session.commit() session.refresh(profile) return profile @users_router.get('/users/me', response_model=UserWithProfile) def get_current_user(user: User = Depends(auth_handler.get_current_user), session=Depends(get_session)): userWithProfile = session.get(User, user.id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") return userWithProfile # Get User by ID @users_router.get(\"/users/{user_id}\", response_model=UserWithProfile) def get_user(user_id: int, session=Depends(get_session)) -> User: user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") return user # Delete User @users_router.delete(\"/users/{user_id}\") def delete_user(user_id: int, session=Depends(get_session)) -> TypedDict('Response', {\"message\": str}): user = session.get(User, user_id) if not user: raise HTTPException(status_code=404, detail=\"User not found\") session.delete(user) session.commit() return {\"message\": \"User deleted successfully\"} @users_router.post('/registration') def register(user_data: UserDefault, profile_data: UserProfile, session=Depends(get_session)) -> TypedDict('Response', {\"status\": int, \"message\": str}): users = session.exec(select(User)).all() if any(x.username == user_data.username for x in users): raise HTTPException(status_code=400, detail='Username is taken') hashed_pwd = auth_handler.get_password_hash(user_data.password) profile = UserProfile(**profile_data.dict()) session.add(profile) session.commit() session.refresh(profile) user = User(password=hashed_pwd, username=user_data.username) user.profile = profile session.add(user) session.commit() session.refresh(user) return {\"status\": 201, \"message\": \"User created successfully\"} @users_router.post('/login') def login(user: UserDefault) -> TypedDict('Response', {\"token\": str}): user_found = find_user(user.username) if not user_found: raise HTTPException(status_code=401, detail='Invalid username and/or password') verified = auth_handler.verify_password(user.password, user_found.password) if not verified: raise HTTPException(status_code=401, detail='Invalid username and/or password') token = auth_handler.encode_token(user_found.username) return {'token': token}","title":"\u042d\u043d\u0434\u043f\u043e\u0438\u043d\u0442\u044b (endpoints/team.py, users.py)"},{"location":"report1/#dbpy-env","text":"\u041a\u043e\u0434 \u0441\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u044f \u0441 \u0411\u0414. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : from sqlmodel import SQLModel, Session, create_engine from dotenv import load_dotenv import os load_dotenv() db_url = os.getenv(\"DATABASE_URL\") engine = create_engine(db_url, echo=True) def init_db(): SQLModel.metadata.create_all(engine) def get_session(): with Session(engine) as session: yield session DATABASE_URL=postgresql://postgres:admin@localhost/postgres","title":"\u0421\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0441 \u0411\u0414 (db.py, .env)"},{"location":"report1/#authpy","text":"\u0410\u0443\u0442\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438 \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439. \u041b\u0438\u0441\u0442\u0438\u043d\u0433 \u043a\u043e\u0434\u0430 : import datetime from fastapi import Security, HTTPException from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials from passlib.context import CryptContext import jwt from starlette import status from repos.users import find_user class AuthHandler: security = HTTPBearer() pwd_context = CryptContext(schemes=['bcrypt']) secret = 'very-very-secret-key' def get_password_hash(self, password): return self.pwd_context.hash(password) def verify_password(self, pwd, hashed_pwd): return self.pwd_context.verify(pwd, hashed_pwd) def encode_token(self, user_id): payload = { 'exp': datetime.datetime.utcnow() + datetime.timedelta(hours=24), 'iat': datetime.datetime.utcnow(), 'sub': user_id } return jwt.encode(payload, self.secret, algorithm='HS256') def decode_token(self, token): try: payload = jwt.decode(token, self.secret, algorithms=['HS256']) return payload['sub'] except jwt.ExpiredSignatureError: raise HTTPException(status_code=401, detail='Expired signature') except jwt.InvalidTokenError: raise HTTPException(status_code=401, detail='Invalid token') def auth_wrapper(self, auth: HTTPAuthorizationCredentials = Security(security)): return self.decode_token(auth.credentials) def get_current_user(self, auth: HTTPAuthorizationCredentials = Security(security)): credentials_exception = HTTPException( status_code=status.HTTP_401_UNAUTHORIZED, detail='Could not validate credentials' ) username = self.decode_token(auth.credentials) if username is None: raise credentials_exception user = find_user(username) if user is None: raise credentials_exception return user","title":"\u0410\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u0435\u0439 (auth.py)"},{"location":"report2/","text":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 2 \u0426\u0435\u043b\u044c \u0440\u0430\u0431\u043e\u0442\u044b : \u043f\u043e\u043d\u044f\u0442\u044c \u043e\u0442\u043b\u0438\u0447\u0438\u044f \u043f\u043e\u0442\u043e\u043a\u0430\u043c\u0438 \u0438 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430\u043c\u0438 \u0438 \u043f\u043e\u043d\u044f\u0442\u044c, \u0447\u0442\u043e \u0442\u0430\u043a\u043e\u0435 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u043e\u0441\u0442\u044c \u0432 Python. \u0417\u0430\u0434\u0430\u043d\u0438\u0435 1 \u0417\u0430\u0434\u0430\u0447\u0430 : \u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u0442\u0440\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u043d\u0430 Python, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0438\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432: threading, multiprocessing \u0438 async. \u041a\u0430\u0436\u0434\u0430\u044f \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u0440\u0435\u0448\u0430\u0442\u044c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0441\u0443\u043c\u043c\u0443 \u0432\u0441\u0435\u0445 \u0447\u0438\u0441\u0435\u043b \u043e\u0442 1 \u0434\u043e 1000000. \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u0430\u0434\u0430\u0447 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. \u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438. task1_threading.py : import threading # \u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u043f\u043e\u0442\u043e\u043a\u0435 \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u044b def calculate_sum(start, end, result): partial_sum = sum(range(start, end)) # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b result.append(partial_sum) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b \u0432 \u043e\u0431\u0449\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 def main(): num_threads = 4 # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0442\u043e\u043a\u043e\u0432 chunk_size = 1000000 // num_threads # \u0420\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u0442\u043e\u043a\u0430 threads = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043f\u043e\u0442\u043e\u043a\u043e\u0432 result = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u044b\u0445 \u0441\u0443\u043c\u043c # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for i in range(num_threads): start = i * chunk_size + 1 # \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 end = (i + 1) * chunk_size + 1 # \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 thread = threading.Thread(target=calculate_sum, args=(start, end, result)) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430 threads.append(thread) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a thread.start() # \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u043e\u0442\u043e\u043a\u0430 # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for thread in threads: thread.join() # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u0449\u0435\u0439 \u0441\u0443\u043c\u043c\u044b total_sum = sum(result) print(\"Total sum:\", total_sum) if __name__ == \"__main__\": import time start_time = time.time() main() print(\"Execution time:\", time.time() - start_time) task1_asyncio.py : import asyncio # \u0410\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u044b async def calculate_sum(start, end): return sum(range(start, end)) async def main(): num_tasks = 4 # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0437\u0430\u0434\u0430\u0447 chunk_size = 1000000 // num_tasks # \u0420\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0437\u0430\u0434\u0430\u0447\u0438 tasks = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447 # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a \u0437\u0430\u0434\u0430\u0447 for i in range(num_tasks): start = i * chunk_size + 1 # \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 end = (i + 1) * chunk_size + 1 # \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 task = asyncio.create_task(calculate_sum(start, end)) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u0447\u0438 tasks.append(task) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u0447\u0438 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a partial_sums = await asyncio.gather(*tasks) # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u0437\u0430\u0434\u0430\u0447 \u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 total_sum = sum(partial_sums) # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u0449\u0435\u0439 \u0441\u0443\u043c\u043c\u044b print(\"Total sum:\", total_sum) if __name__ == \"__main__\": import time start_time = time.time() asyncio.run(main()) print(\"Execution time:\", time.time() - start_time) task1_multiprocessing.py : from multiprocessing import Process, Queue # \u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u044b def calculate_sum(start, end, result_queue): partial_sum = sum(range(start, end)) # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b result_queue.put(partial_sum) # \u041f\u043e\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b \u0432 \u043e\u0447\u0435\u0440\u0435\u0434\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 def main(): num_processes = 4 # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 chunk_size = 1000000 // num_processes # \u0420\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 processes = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 result_queue = Queue() # \u041e\u0447\u0435\u0440\u0435\u0434\u044c \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u044b\u0445 \u0441\u0443\u043c\u043c # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for i in range(num_processes): start = i * chunk_size + 1 # \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 end = (i + 1) * chunk_size + 1 # \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 process = Process(target=calculate_sum, args=(start, end, result_queue)) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 processes.append(process) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a process.start() # \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() total_sum = 0 while not result_queue.empty(): total_sum += result_queue.get() print(\"Total sum:\", total_sum) if __name__ == \"__main__\": import time start_time = time.time() main() print(\"Execution time:\", time.time() - start_time) Task 1: Threading - 0.055 +- Multiprocessing - 0.32 +- Asyncio - 0.0467 +- Multiprocessing - \u0441\u0430\u043c\u044b\u0439 \u043c\u0435\u0434\u043b\u0435\u043d\u043d\u044b\u0439 \u0437\u0430 \u0441\u0447\u0435\u0442 \u0442\u043e\u0433\u043e, \u0447\u0442\u043e \u043e\u043d \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u0441\u0441, \u0430 \u043d\u0435 \u043f\u043e\u0442\u043e\u043a, \u0430 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430\u043c\u0438 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u0447\u0435\u043c \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430\u043c\u0438. Threading \u0438 Asyncio \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u043d\u043e Asyncio \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u0447\u0435\u043c Threading, \u0442\u0430\u043a \u043a\u0430\u043a \u043e\u043d \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u043e\u0434\u0438\u043d \u043f\u043e\u0442\u043e\u043a, \u0430 \u043d\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e. \u0417\u0430\u0434\u0430\u043d\u0438\u0435 2 \u0417\u0430\u0434\u0430\u0447\u0430 : \u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443 \u043d\u0430 Python \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0441 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432 threading, multiprocessing \u0438 async. \u041a\u0430\u0436\u0434\u0430\u044f \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u043f\u0430\u0440\u0441\u0438\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u0441 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0432\u0435\u0431-\u0441\u0430\u0439\u0442\u043e\u0432, \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0438\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445. task2_threading.py : import threading from task2.handlers import ( parse_all_urls, data_handlers ) def parse_and_save(): # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u043e\u0442\u043e\u043a\u0438 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e URL threads = [] for category, handler_func in data_handlers.items(): url = f\"https://async-laboratory-work.tiiny.site/{category}\" print(url) thread = threading.Thread(target=parse_all_urls, args=(handler_func, url, 5)) threads.append(thread) thread.start() # \u0416\u0434\u0435\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for thread in threads: thread.join() if __name__ == \"__main__\": import time start_time = time.time() parse_and_save() print(\"Execution time:\", time.time() - start_time) task2_multiprocessing.py : import multiprocessing from task2.handlers import parse_all_urls, data_handlers def parse_and_save(): # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u044b \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e URL processes = [] for category, handler_func in data_handlers.items(): url = f\"https://async-laboratory-work.tiiny.site/{category}\" print(url) process = multiprocessing.Process(target=parse_all_urls, args=(handler_func, url, 5)) processes.append(process) process.start() # \u0416\u0434\u0435\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() if __name__ == \"__main__\": import time start_time = time.time() parse_and_save() print(\"Execution time:\", time.time() - start_time) task2_asyncio.py : import multiprocessing from task2.handlers import parse_all_urls, data_handlers def parse_and_save(): # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u044b \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e URL processes = [] for category, handler_func in data_handlers.items(): url = f\"https://async-laboratory-work.tiiny.site/{category}\" print(url) process = multiprocessing.Process(target=parse_all_urls, args=(handler_func, url, 5)) processes.append(process) process.start() # \u0416\u0434\u0435\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() if __name__ == \"__main__\": import time start_time = time.time() parse_and_save() print(\"Execution time:\", time.time() - start_time) handlers.py : import json import psycopg2 import requests from bs4 import BeautifulSoup def get_connection(): return psycopg2.connect( dbname=\"async_lab\", user=\"postgres\", password=\"admin\", host=\"localhost\", port=\"5432\" ) def parse_and_save_users(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') users = [] conn = get_connection() with conn.cursor() as cursor: for li in soup.select('ul > li'): user = {} username = li.select_one('.username').text password = li.select_one('.password').text profile_id = int(li.select_one('.profile-id').text) users.append(user) cursor.execute( \"INSERT INTO \\\"user\\\" (username, password, profile_id) VALUES (%s, %s, %s)\", (username, password, profile_id) ) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_projects(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') projects = [] conn = get_connection() cursor = conn.cursor() for li in soup.select('ul > li'): project = {} project_name = li.select_one('.name').text project_description = li.select_one('.description').text project_expected_result = li.select_one('.expected-result').text project_team_id = int(li.select_one('.team-id').text) projects.append(project) cursor.execute(\"INSERT INTO project (name, description, expected_result, team_id) VALUES (%s, %s, %s, %s)\", (project_name, project_description, project_expected_result, project_team_id)) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_tasks(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') conn = get_connection() with conn.cursor() as cursor: for li in soup.select('ul > li'): task_name = li.select_one('.name').text task_description = li.select_one('.description').text task_deadline = li.select_one('.deadline').text project_id = int(li.select_one('.project-id').text) cursor.execute( \"INSERT INTO task (name, description, deadline, project_id) VALUES (%s, %s, %s, %s)\", (task_name, task_description, task_deadline, project_id) ) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_userprofiles(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') conn = get_connection() with conn.cursor() as cursor: for li in soup.select('ul > li'): avatar = li.select_one('.avatar').text birth_date = li.select_one('.birth_date').text skills = [skill_li.text for skill_li in li.select('ol.skills > li')] cursor.execute( \"INSERT INTO userprofile (avatar, birth_date, skills) VALUES (%s, %s, %s)\", (avatar, birth_date, json.dumps(skills)) ) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_teams(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') conn = get_connection() cursor = conn.cursor() for li in soup.select('ul > li'): team_name = li.select_one('.name').text cursor.execute( \"INSERT INTO team (name) VALUES (%s)\", (team_name,) ) conn.commit() cursor.close() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_all_urls(handle_func, base, count): for i in range(1, count + 1): url = f\"{base}{i}.html\" handle_func(url) data_handlers = { \"tasks\": parse_and_save_tasks, \"projects\": parse_and_save_projects, \"users\": parse_and_save_users, \"teams\": parse_and_save_teams, \"userprofiles\": parse_and_save_userprofiles, } \u041f\u043e\u043c\u0435\u0442\u043a\u0430 :\u042d\u0442\u043e\u0442 \u043a\u043e\u0434 \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u0442 \u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u044b\u0439 \u043f\u0430\u0440\u0441\u0435\u0440 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u0438\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 PostgreSQL. \u041e\u043d \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 requests \u0434\u043b\u044f HTTP-\u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432, BeautifulSoup \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 HTML, \u0438 psycopg2 \u0434\u043b\u044f \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f \u0441 \u0431\u0430\u0437\u043e\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 PostgreSQL. async_handlers.py : import json import aiohttp from bs4 import BeautifulSoup import psycopg2 import asyncio import aiopg asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy()) async def get_connection(): # \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u043a \u0431\u0430\u0437\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 return await aiopg.connect( dsn=\"dbname=async_lab user=postgres password=admin host=localhost port=5432\" ) async def parse_and_save_users(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): username = li.select_one('.username').text password = li.select_one('.password').text profile_id = int(li.select_one('.profile-id').text) await cursor.execute( \"INSERT INTO \\\"user\\\" (username, password, profile_id) VALUES (%s, %s, %s)\", (username, password, profile_id) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_projects(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): project_name = li.select_one('.name').text project_description = li.select_one('.description').text project_expected_result = li.select_one('.expected-result').text project_team_id = int(li.select_one('.team-id').text) await cursor.execute( \"INSERT INTO project (name, description, expected_result, team_id) VALUES (%s, %s, %s, %s)\", (project_name, project_description, project_expected_result, project_team_id)) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_tasks(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): task_name = li.select_one('.name').text task_description = li.select_one('.description').text task_deadline = li.select_one('.deadline').text project_id = int(li.select_one('.project-id').text) await cursor.execute( \"INSERT INTO task (name, description, deadline, project_id) VALUES (%s, %s, %s, %s)\", (task_name, task_description, task_deadline, project_id) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_userprofiles(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): avatar = li.select_one('.avatar').text birth_date = li.select_one('.birth_date').text skills = [skill_li.text for skill_li in li.select('ol.skills > li')] await cursor.execute( \"INSERT INTO userprofile (avatar, birth_date, skills) VALUES (%s, %s, %s)\", (avatar, birth_date, json.dumps(skills)) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_teams(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): team_name = li.select_one('.name').text await cursor.execute( \"INSERT INTO team (name) VALUES (%s)\", (team_name,) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_all_urls(handler_func, base, count): async with aiohttp.ClientSession() as session: for i in range(1, count + 1): url = f\"{base}{i}.html\" try: await handler_func(session, url) except Exception as e: print(f\"Error: {e}\") await asyncio.sleep(1) data_handlers = { \"tasks\": parse_and_save_tasks, \"projects\": parse_and_save_projects, \"users\": parse_and_save_users, \"teams\": parse_and_save_teams, \"userprofiles\": parse_and_save_userprofiles, } \u041f\u043e\u043c\u0435\u0442\u043a\u0430 :\u0414\u0430\u043d\u043d\u044b\u0439 \u043a\u043e\u0434 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u043e\u0435 \u0438\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u044d\u0442\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 PostgreSQL Task 2: (5 \u0441\u0442\u0440\u0430\u043d\u0438\u0446, \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 100 \u0437\u0430\u043f\u0438\u0441\u0435\u0439) Threading - 4.021 Multiprocessing - 4.244 Asyncio - 3.88 \u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, Asyncio \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u0447\u0435\u043c Threading \u0438 Multiprocessing, \u0442\u0430\u043a \u043a\u0430\u043a \u043f\u0440\u0438 \u0437\u0430\u043f\u0438\u0441\u0438 \u0432 \u0411\u0414 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442 \u043c\u043d\u043e\u0433\u043e \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0439 \u0432\u0432\u043e\u0434\u0430/\u0432\u044b\u0432\u043e\u0434\u0430, \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043e\u0442 \u043d\u0438\u0445 \u043d\u0435\u0432\u0435\u043b\u0438\u043a\u0430","title":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 2"},{"location":"report2/#2","text":"\u0426\u0435\u043b\u044c \u0440\u0430\u0431\u043e\u0442\u044b : \u043f\u043e\u043d\u044f\u0442\u044c \u043e\u0442\u043b\u0438\u0447\u0438\u044f \u043f\u043e\u0442\u043e\u043a\u0430\u043c\u0438 \u0438 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430\u043c\u0438 \u0438 \u043f\u043e\u043d\u044f\u0442\u044c, \u0447\u0442\u043e \u0442\u0430\u043a\u043e\u0435 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u043e\u0441\u0442\u044c \u0432 Python.","title":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 2"},{"location":"report2/#1","text":"\u0417\u0430\u0434\u0430\u0447\u0430 : \u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u0442\u0440\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u043d\u0430 Python, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0438\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432: threading, multiprocessing \u0438 async. \u041a\u0430\u0436\u0434\u0430\u044f \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u0440\u0435\u0448\u0430\u0442\u044c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0441\u0443\u043c\u043c\u0443 \u0432\u0441\u0435\u0445 \u0447\u0438\u0441\u0435\u043b \u043e\u0442 1 \u0434\u043e 1000000. \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u0430\u0434\u0430\u0447 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. \u0420\u0435\u0430\u043b\u0438\u0437\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438. task1_threading.py : import threading # \u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u043f\u043e\u0442\u043e\u043a\u0435 \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u044b def calculate_sum(start, end, result): partial_sum = sum(range(start, end)) # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b result.append(partial_sum) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b \u0432 \u043e\u0431\u0449\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 def main(): num_threads = 4 # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u0442\u043e\u043a\u043e\u0432 chunk_size = 1000000 // num_threads # \u0420\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u043e\u0442\u043e\u043a\u0430 threads = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043f\u043e\u0442\u043e\u043a\u043e\u0432 result = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u044b\u0445 \u0441\u0443\u043c\u043c # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for i in range(num_threads): start = i * chunk_size + 1 # \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 end = (i + 1) * chunk_size + 1 # \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 thread = threading.Thread(target=calculate_sum, args=(start, end, result)) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430 threads.append(thread) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a thread.start() # \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u043e\u0442\u043e\u043a\u0430 # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for thread in threads: thread.join() # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u0449\u0435\u0439 \u0441\u0443\u043c\u043c\u044b total_sum = sum(result) print(\"Total sum:\", total_sum) if __name__ == \"__main__\": import time start_time = time.time() main() print(\"Execution time:\", time.time() - start_time) task1_asyncio.py : import asyncio # \u0410\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u0430\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u044b async def calculate_sum(start, end): return sum(range(start, end)) async def main(): num_tasks = 4 # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0437\u0430\u0434\u0430\u0447 chunk_size = 1000000 // num_tasks # \u0420\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0437\u0430\u0434\u0430\u0447\u0438 tasks = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447 # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a \u0437\u0430\u0434\u0430\u0447 for i in range(num_tasks): start = i * chunk_size + 1 # \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 end = (i + 1) * chunk_size + 1 # \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 task = asyncio.create_task(calculate_sum(start, end)) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u0447\u0438 tasks.append(task) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u0447\u0438 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a partial_sums = await asyncio.gather(*tasks) # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u0437\u0430\u0434\u0430\u0447 \u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 total_sum = sum(partial_sums) # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u0449\u0435\u0439 \u0441\u0443\u043c\u043c\u044b print(\"Total sum:\", total_sum) if __name__ == \"__main__\": import time start_time = time.time() asyncio.run(main()) print(\"Execution time:\", time.time() - start_time) task1_multiprocessing.py : from multiprocessing import Process, Queue # \u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0442\u044c\u0441\u044f \u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0435 \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u0441\u0443\u043c\u043c\u044b def calculate_sum(start, end, result_queue): partial_sum = sum(range(start, end)) # \u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b result_queue.put(partial_sum) # \u041f\u043e\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e\u0439 \u0441\u0443\u043c\u043c\u044b \u0432 \u043e\u0447\u0435\u0440\u0435\u0434\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 def main(): num_processes = 4 # \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 chunk_size = 1000000 // num_processes # \u0420\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 processes = [] # \u0421\u043f\u0438\u0441\u043e\u043a \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 result_queue = Queue() # \u041e\u0447\u0435\u0440\u0435\u0434\u044c \u0434\u043b\u044f \u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u044b\u0445 \u0441\u0443\u043c\u043c # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u043a \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for i in range(num_processes): start = i * chunk_size + 1 # \u041d\u0430\u0447\u0430\u043b\u044c\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 end = (i + 1) * chunk_size + 1 # \u041a\u043e\u043d\u0435\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u043f\u043e\u0440\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 process = Process(target=calculate_sum, args=(start, end, result_queue)) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 processes.append(process) # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a process.start() # \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() total_sum = 0 while not result_queue.empty(): total_sum += result_queue.get() print(\"Total sum:\", total_sum) if __name__ == \"__main__\": import time start_time = time.time() main() print(\"Execution time:\", time.time() - start_time)","title":"\u0417\u0430\u0434\u0430\u043d\u0438\u0435 1"},{"location":"report2/#task-1","text":"Threading - 0.055 +- Multiprocessing - 0.32 +- Asyncio - 0.0467 +- Multiprocessing - \u0441\u0430\u043c\u044b\u0439 \u043c\u0435\u0434\u043b\u0435\u043d\u043d\u044b\u0439 \u0437\u0430 \u0441\u0447\u0435\u0442 \u0442\u043e\u0433\u043e, \u0447\u0442\u043e \u043e\u043d \u0441\u043e\u0437\u0434\u0430\u0435\u0442 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u0441\u0441, \u0430 \u043d\u0435 \u043f\u043e\u0442\u043e\u043a, \u0430 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430\u043c\u0438 \u0437\u0430\u043d\u0438\u043c\u0430\u0435\u0442 \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u0438, \u0447\u0435\u043c \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u0430\u043c\u0438. Threading \u0438 Asyncio \u0440\u0430\u0431\u043e\u0442\u0430\u044e\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u043d\u043e Asyncio \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u0447\u0435\u043c Threading, \u0442\u0430\u043a \u043a\u0430\u043a \u043e\u043d \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u043e\u0434\u0438\u043d \u043f\u043e\u0442\u043e\u043a, \u0430 \u043d\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e.","title":"Task 1:"},{"location":"report2/#2_1","text":"\u0417\u0430\u0434\u0430\u0447\u0430 : \u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443 \u043d\u0430 Python \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0441 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432 threading, multiprocessing \u0438 async. \u041a\u0430\u0436\u0434\u0430\u044f \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u043f\u0430\u0440\u0441\u0438\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u0441 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0432\u0435\u0431-\u0441\u0430\u0439\u0442\u043e\u0432, \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u0438\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445. task2_threading.py : import threading from task2.handlers import ( parse_all_urls, data_handlers ) def parse_and_save(): # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u043e\u0442\u043e\u043a\u0438 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e URL threads = [] for category, handler_func in data_handlers.items(): url = f\"https://async-laboratory-work.tiiny.site/{category}\" print(url) thread = threading.Thread(target=parse_all_urls, args=(handler_func, url, 5)) threads.append(thread) thread.start() # \u0416\u0434\u0435\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for thread in threads: thread.join() if __name__ == \"__main__\": import time start_time = time.time() parse_and_save() print(\"Execution time:\", time.time() - start_time) task2_multiprocessing.py : import multiprocessing from task2.handlers import parse_all_urls, data_handlers def parse_and_save(): # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u044b \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e URL processes = [] for category, handler_func in data_handlers.items(): url = f\"https://async-laboratory-work.tiiny.site/{category}\" print(url) process = multiprocessing.Process(target=parse_all_urls, args=(handler_func, url, 5)) processes.append(process) process.start() # \u0416\u0434\u0435\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() if __name__ == \"__main__\": import time start_time = time.time() parse_and_save() print(\"Execution time:\", time.time() - start_time) task2_asyncio.py : import multiprocessing from task2.handlers import parse_all_urls, data_handlers def parse_and_save(): # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u044b \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u043a\u0430\u0436\u0434\u043e\u0433\u043e URL processes = [] for category, handler_func in data_handlers.items(): url = f\"https://async-laboratory-work.tiiny.site/{category}\" print(url) process = multiprocessing.Process(target=parse_all_urls, args=(handler_func, url, 5)) processes.append(process) process.start() # \u0416\u0434\u0435\u043c \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() if __name__ == \"__main__\": import time start_time = time.time() parse_and_save() print(\"Execution time:\", time.time() - start_time) handlers.py : import json import psycopg2 import requests from bs4 import BeautifulSoup def get_connection(): return psycopg2.connect( dbname=\"async_lab\", user=\"postgres\", password=\"admin\", host=\"localhost\", port=\"5432\" ) def parse_and_save_users(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') users = [] conn = get_connection() with conn.cursor() as cursor: for li in soup.select('ul > li'): user = {} username = li.select_one('.username').text password = li.select_one('.password').text profile_id = int(li.select_one('.profile-id').text) users.append(user) cursor.execute( \"INSERT INTO \\\"user\\\" (username, password, profile_id) VALUES (%s, %s, %s)\", (username, password, profile_id) ) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_projects(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') projects = [] conn = get_connection() cursor = conn.cursor() for li in soup.select('ul > li'): project = {} project_name = li.select_one('.name').text project_description = li.select_one('.description').text project_expected_result = li.select_one('.expected-result').text project_team_id = int(li.select_one('.team-id').text) projects.append(project) cursor.execute(\"INSERT INTO project (name, description, expected_result, team_id) VALUES (%s, %s, %s, %s)\", (project_name, project_description, project_expected_result, project_team_id)) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_tasks(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') conn = get_connection() with conn.cursor() as cursor: for li in soup.select('ul > li'): task_name = li.select_one('.name').text task_description = li.select_one('.description').text task_deadline = li.select_one('.deadline').text project_id = int(li.select_one('.project-id').text) cursor.execute( \"INSERT INTO task (name, description, deadline, project_id) VALUES (%s, %s, %s, %s)\", (task_name, task_description, task_deadline, project_id) ) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_userprofiles(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') conn = get_connection() with conn.cursor() as cursor: for li in soup.select('ul > li'): avatar = li.select_one('.avatar').text birth_date = li.select_one('.birth_date').text skills = [skill_li.text for skill_li in li.select('ol.skills > li')] cursor.execute( \"INSERT INTO userprofile (avatar, birth_date, skills) VALUES (%s, %s, %s)\", (avatar, birth_date, json.dumps(skills)) ) conn.commit() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_and_save_teams(url): response = requests.get(url) soup = BeautifulSoup(response.text, 'html.parser') conn = get_connection() cursor = conn.cursor() for li in soup.select('ul > li'): team_name = li.select_one('.name').text cursor.execute( \"INSERT INTO team (name) VALUES (%s)\", (team_name,) ) conn.commit() cursor.close() conn.close() print(f\"Data from {url} parsed and saved to database.\") def parse_all_urls(handle_func, base, count): for i in range(1, count + 1): url = f\"{base}{i}.html\" handle_func(url) data_handlers = { \"tasks\": parse_and_save_tasks, \"projects\": parse_and_save_projects, \"users\": parse_and_save_users, \"teams\": parse_and_save_teams, \"userprofiles\": parse_and_save_userprofiles, } \u041f\u043e\u043c\u0435\u0442\u043a\u0430 :\u042d\u0442\u043e\u0442 \u043a\u043e\u0434 \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u0435\u0442 \u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u044b\u0439 \u043f\u0430\u0440\u0441\u0435\u0440 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u0438\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 PostgreSQL. \u041e\u043d \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 requests \u0434\u043b\u044f HTTP-\u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432, BeautifulSoup \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 HTML, \u0438 psycopg2 \u0434\u043b\u044f \u0432\u0437\u0430\u0438\u043c\u043e\u0434\u0435\u0439\u0441\u0442\u0432\u0438\u044f \u0441 \u0431\u0430\u0437\u043e\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 PostgreSQL. async_handlers.py : import json import aiohttp from bs4 import BeautifulSoup import psycopg2 import asyncio import aiopg asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy()) async def get_connection(): # \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u043a \u0431\u0430\u0437\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 return await aiopg.connect( dsn=\"dbname=async_lab user=postgres password=admin host=localhost port=5432\" ) async def parse_and_save_users(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): username = li.select_one('.username').text password = li.select_one('.password').text profile_id = int(li.select_one('.profile-id').text) await cursor.execute( \"INSERT INTO \\\"user\\\" (username, password, profile_id) VALUES (%s, %s, %s)\", (username, password, profile_id) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_projects(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): project_name = li.select_one('.name').text project_description = li.select_one('.description').text project_expected_result = li.select_one('.expected-result').text project_team_id = int(li.select_one('.team-id').text) await cursor.execute( \"INSERT INTO project (name, description, expected_result, team_id) VALUES (%s, %s, %s, %s)\", (project_name, project_description, project_expected_result, project_team_id)) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_tasks(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): task_name = li.select_one('.name').text task_description = li.select_one('.description').text task_deadline = li.select_one('.deadline').text project_id = int(li.select_one('.project-id').text) await cursor.execute( \"INSERT INTO task (name, description, deadline, project_id) VALUES (%s, %s, %s, %s)\", (task_name, task_description, task_deadline, project_id) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_userprofiles(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): avatar = li.select_one('.avatar').text birth_date = li.select_one('.birth_date').text skills = [skill_li.text for skill_li in li.select('ol.skills > li')] await cursor.execute( \"INSERT INTO userprofile (avatar, birth_date, skills) VALUES (%s, %s, %s)\", (avatar, birth_date, json.dumps(skills)) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_and_save_teams(session, url): async with session.get(url) as response: html_content = await response.text() soup = BeautifulSoup(html_content, 'html.parser') async with await get_connection() as conn: async with conn.cursor() as cursor: for li in soup.select('ul > li'): team_name = li.select_one('.name').text await cursor.execute( \"INSERT INTO team (name) VALUES (%s)\", (team_name,) ) await cursor.execute(\"COMMIT\") print(f\"Data from {url} parsed and saved to database.\") async def parse_all_urls(handler_func, base, count): async with aiohttp.ClientSession() as session: for i in range(1, count + 1): url = f\"{base}{i}.html\" try: await handler_func(session, url) except Exception as e: print(f\"Error: {e}\") await asyncio.sleep(1) data_handlers = { \"tasks\": parse_and_save_tasks, \"projects\": parse_and_save_projects, \"users\": parse_and_save_users, \"teams\": parse_and_save_teams, \"userprofiles\": parse_and_save_userprofiles, } \u041f\u043e\u043c\u0435\u0442\u043a\u0430 :\u0414\u0430\u043d\u043d\u044b\u0439 \u043a\u043e\u0434 \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u043e\u0435 \u0438\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u044d\u0442\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 PostgreSQL","title":"\u0417\u0430\u0434\u0430\u043d\u0438\u0435 2"},{"location":"report2/#task-2-5-100","text":"Threading - 4.021 Multiprocessing - 4.244 Asyncio - 3.88 \u0412 \u0434\u0430\u043d\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435, Asyncio \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0431\u044b\u0441\u0442\u0440\u0435\u0435, \u0447\u0435\u043c Threading \u0438 Multiprocessing, \u0442\u0430\u043a \u043a\u0430\u043a \u043f\u0440\u0438 \u0437\u0430\u043f\u0438\u0441\u0438 \u0432 \u0411\u0414 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442 \u043c\u043d\u043e\u0433\u043e \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0439 \u0432\u0432\u043e\u0434\u0430/\u0432\u044b\u0432\u043e\u0434\u0430, \u043f\u0440\u0438 \u044d\u0442\u043e\u043c \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043e\u0442 \u043d\u0438\u0445 \u043d\u0435\u0432\u0435\u043b\u0438\u043a\u0430","title":"Task 2: (5 \u0441\u0442\u0440\u0430\u043d\u0438\u0446, \u0432 \u043a\u0430\u0436\u0434\u043e\u0439 100 \u0437\u0430\u043f\u0438\u0441\u0435\u0439)"},{"location":"report3/","text":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 3 \u0426\u0435\u043b\u044c \u0440\u0430\u0431\u043e\u0442\u044b : \u043d\u0430\u0443\u0447\u0438\u0442\u044c\u0441\u044f \u0443\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0442\u044c FastAPI \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0432 Docker, \u0438\u043d\u0442\u0435\u0433\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0441\u0435\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0431\u0430\u0437\u043e\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0441\u0435\u0440 \u0447\u0435\u0440\u0435\u0437 API \u0438 \u043e\u0447\u0435\u0440\u0435\u0434\u044c. docker-compose.yml : version: \"3.8\" services: async_lab: build: ./async_lab ports: - \"9090:8080\" expose: - \"9090\" environment: DATABASE_USER: postgres DATABASE_PASSWORD: postgres DATABASE_HOST: db depends_on: - db fast_api_lab: build: ./fast_api_lab ports: - \"8080:8080\" expose: - \"8080\" command: uvicorn main:app --host 0.0.0.0 --port 8080 environment: DATABASE_URL: postgresql://postgres:postgres@db:5432/warriors_db CELERY_BROKER_URL: redis://redis:6379/0 CELERY_RESULT_BACKEND: redis://redis:6379/0 depends_on: - db - redis db: image: postgres:13 volumes: - postgres_data:/var/lib/postgresql/data - ./init.sql:/docker-entrypoint-initdb.d/init.sql ports: - \"5433:5432\" environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres POSTGRES_DB: warriors_db redis: image: redis:latest ports: - \"6379:6379\" volumes: - redis_data:/data celery_worker: build: ./fast_api_lab depends_on: - redis - fast_api_lab - db command: celery -A worker:celery_app worker --loglevel=info --pool=solo environment: CELERY_BROKER_URL: redis://redis:6379/0 CELERY_RESULT_BACKEND: redis://redis:6379/0 DATABASE_URL: postgresql://postgres:postgres@db:5432/warriors_db celery_beat: build: ./fast_api_lab depends_on: - redis - fast_api_lab - db command: celery -A worker:celery_app beat --loglevel=info environment: CELERY_BROKER_URL: redis://redis:6379/0 CELERY_RESULT_BACKEND: redis://redis:6379/0 DATABASE_URL: postgresql://postgres:postgres@db:5432/warriors_db celery_dashboard: build: ./fast_api_lab command: celery --broker=redis://redis:6379/0 flower --port=5555 ports: - 5556:5555 environment: - CELERY_BROKER_URL=redis://redis:6379/0 - CELERY_RESULT_BACKEND=redis://redis:6379/0 depends_on: - fast_api_lab - redis - celery_worker volumes: postgres_data: redis_data: worker.py : Celery from celery import Celery from sqlmodel import Session, create_engine, text import os import requests from fastapi import HTTPException engine = create_engine(os.getenv(\"DATABASE_URL\"), echo=True) print(os.getenv(\"CELERY_BROKER_URL\"), os.getenv(\"CELERY_RESULT_BACKEND\")) celery_app = Celery('fast_api_lab', broker=os.getenv(\"CELERY_BROKER_URL\", 'redis://localhost:6379/0'), backend=os.getenv(\"CELERY_RESULT_BACKEND\", 'redis://localhost:6379/0')) celery_app.conf.update( task_serializer='json', result_serializer='json', accept_content=['json'], timezone='UTC', enable_utc=True, beat_schedule={ 'count-records-every-hour': { 'task': 'count_records_task', 'schedule': 3.0, # \u043a\u0430\u0436\u0434\u044b\u0439 \u0447\u0430\u0441 }, }, ) @celery_app.task(name=\"parse_urls_task\") def parse_urls_task(category: str): try: response = requests.post(f\"http://async_lab:8080/parse/{category}\") return response.json() except requests.RequestException as e: raise HTTPException(status_code=500, detail=str(e)) @celery_app.task(name=\"count_records_task\") def count_records_task(): table_names = [\"project\", \"task\", \"team\", \"user\", \"userprofile\"] counts = {} with Session(engine) as session: for table_name in table_names: statement = text(f\"SELECT COUNT(*) FROM {table_name}\") result = session.execute(statement).one() counts[table_name] = result[0] return counts main.py : @app.post(\"/parse/{category}\") async def parse(category: str): try: handler_func = data_handlers.get(category) if not handler_func: raise HTTPException(status_code=404, detail=\"Category not found\") url_to_parse = f\"https://async-laboratory-work.tiiny.site/{category}\" added = await parse_all_urls(handler_func, url_to_parse, 5) return {\"message\": \"Parsing completed\", \"added_count\": added} except requests.RequestException as e: raise HTTPException(status_code=500, detail=str(e))","title":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 3"},{"location":"report3/#3","text":"\u0426\u0435\u043b\u044c \u0440\u0430\u0431\u043e\u0442\u044b : \u043d\u0430\u0443\u0447\u0438\u0442\u044c\u0441\u044f \u0443\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0442\u044c FastAPI \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0432 Docker, \u0438\u043d\u0442\u0435\u0433\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0441\u0435\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0431\u0430\u0437\u043e\u0439 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0442\u044c \u043f\u0430\u0440\u0441\u0435\u0440 \u0447\u0435\u0440\u0435\u0437 API \u0438 \u043e\u0447\u0435\u0440\u0435\u0434\u044c. docker-compose.yml : version: \"3.8\" services: async_lab: build: ./async_lab ports: - \"9090:8080\" expose: - \"9090\" environment: DATABASE_USER: postgres DATABASE_PASSWORD: postgres DATABASE_HOST: db depends_on: - db fast_api_lab: build: ./fast_api_lab ports: - \"8080:8080\" expose: - \"8080\" command: uvicorn main:app --host 0.0.0.0 --port 8080 environment: DATABASE_URL: postgresql://postgres:postgres@db:5432/warriors_db CELERY_BROKER_URL: redis://redis:6379/0 CELERY_RESULT_BACKEND: redis://redis:6379/0 depends_on: - db - redis db: image: postgres:13 volumes: - postgres_data:/var/lib/postgresql/data - ./init.sql:/docker-entrypoint-initdb.d/init.sql ports: - \"5433:5432\" environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres POSTGRES_DB: warriors_db redis: image: redis:latest ports: - \"6379:6379\" volumes: - redis_data:/data celery_worker: build: ./fast_api_lab depends_on: - redis - fast_api_lab - db command: celery -A worker:celery_app worker --loglevel=info --pool=solo environment: CELERY_BROKER_URL: redis://redis:6379/0 CELERY_RESULT_BACKEND: redis://redis:6379/0 DATABASE_URL: postgresql://postgres:postgres@db:5432/warriors_db celery_beat: build: ./fast_api_lab depends_on: - redis - fast_api_lab - db command: celery -A worker:celery_app beat --loglevel=info environment: CELERY_BROKER_URL: redis://redis:6379/0 CELERY_RESULT_BACKEND: redis://redis:6379/0 DATABASE_URL: postgresql://postgres:postgres@db:5432/warriors_db celery_dashboard: build: ./fast_api_lab command: celery --broker=redis://redis:6379/0 flower --port=5555 ports: - 5556:5555 environment: - CELERY_BROKER_URL=redis://redis:6379/0 - CELERY_RESULT_BACKEND=redis://redis:6379/0 depends_on: - fast_api_lab - redis - celery_worker volumes: postgres_data: redis_data: worker.py : Celery from celery import Celery from sqlmodel import Session, create_engine, text import os import requests from fastapi import HTTPException engine = create_engine(os.getenv(\"DATABASE_URL\"), echo=True) print(os.getenv(\"CELERY_BROKER_URL\"), os.getenv(\"CELERY_RESULT_BACKEND\")) celery_app = Celery('fast_api_lab', broker=os.getenv(\"CELERY_BROKER_URL\", 'redis://localhost:6379/0'), backend=os.getenv(\"CELERY_RESULT_BACKEND\", 'redis://localhost:6379/0')) celery_app.conf.update( task_serializer='json', result_serializer='json', accept_content=['json'], timezone='UTC', enable_utc=True, beat_schedule={ 'count-records-every-hour': { 'task': 'count_records_task', 'schedule': 3.0, # \u043a\u0430\u0436\u0434\u044b\u0439 \u0447\u0430\u0441 }, }, ) @celery_app.task(name=\"parse_urls_task\") def parse_urls_task(category: str): try: response = requests.post(f\"http://async_lab:8080/parse/{category}\") return response.json() except requests.RequestException as e: raise HTTPException(status_code=500, detail=str(e)) @celery_app.task(name=\"count_records_task\") def count_records_task(): table_names = [\"project\", \"task\", \"team\", \"user\", \"userprofile\"] counts = {} with Session(engine) as session: for table_name in table_names: statement = text(f\"SELECT COUNT(*) FROM {table_name}\") result = session.execute(statement).one() counts[table_name] = result[0] return counts main.py : @app.post(\"/parse/{category}\") async def parse(category: str): try: handler_func = data_handlers.get(category) if not handler_func: raise HTTPException(status_code=404, detail=\"Category not found\") url_to_parse = f\"https://async-laboratory-work.tiiny.site/{category}\" added = await parse_all_urls(handler_func, url_to_parse, 5) return {\"message\": \"Parsing completed\", \"added_count\": added} except requests.RequestException as e: raise HTTPException(status_code=500, detail=str(e))","title":"\u041b\u0430\u0431\u043e\u0440\u0430\u0442\u043e\u0440\u043d\u0430\u044f \u0440\u0430\u0431\u043e\u0442\u0430 3"}]}